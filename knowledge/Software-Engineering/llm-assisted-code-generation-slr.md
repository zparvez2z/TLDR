---
source_url: https://arxiv.org/pdf/2411.00041
author: Zhiqiang Li, Xiao-Yi Zhang, Zhiming Wang, Ziqi Ye, Wen-jie Jiang, Zan Wang, Gang Yin
date: 31-10-2024
---

# LLM-Assisted Code Generation: A Systematic Literature Review

This paper presents a systematic literature review of 155 studies on Large Language Model (LLM)-assisted code generation published up to May 2024. The review analyzes the field by addressing key research questions regarding common tasks, prevalent techniques, evaluation methods, and existing challenges. The authors provide a comprehensive taxonomy of the current landscape, highlighting trends and identifying gaps in the research. The findings aim to guide future work by outlining promising directions and unresolved issues in this rapidly evolving domain.

*   **Scope:** The review covers 155 papers, focusing on tasks like code generation, completion, translation, and repair.
*   **Techniques:** Dominant techniques for enhancing LLM performance include prompt engineering, fine-tuning on domain-specific data, and Retrieval-Augmented Generation (RAG).
*   **Evaluation:** Evaluation is heavily reliant on automated metrics (e.g., Pass@k, CodeBLEU), but there is a growing need for more robust, human-centric, and functionality-based assessments.
*   **Challenges & Future Directions:** Key challenges include ensuring code correctness and security, managing long context dependencies, and improving model interpretability. Future research should focus on developing better evaluation benchmarks, enhancing security, and creating more interactive and reliable code generation systems.