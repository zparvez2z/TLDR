---
source_url: https://arxiv.org/pdf/2506.04734
author: Matteo Pellegrini
date: 2024-06-07
---

# The Unreasonable Effectiveness of Large Language Models in Zero-Shot Semantic Annotation of Historical Texts

This paper investigates the zero-shot capabilities of Large Language Models (LLMs), specifically GPT-4, for semantic annotation of historical texts. The study compares the performance of LLMs against traditional methods like BERT-based models and dictionary-based approaches on a dataset of 17th-century Jesuit letters. The results demonstrate that LLMs significantly outperform these established methods in identifying and classifying named entities without any specific training. This highlights the transformative potential of LLMs for digital humanities research, providing powerful and efficient tools for analyzing historical documents, despite challenges like prompt engineering.