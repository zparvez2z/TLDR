---
source_url: https://arxiv.org/html/2507.13334v2
author: Lingrui Mei, Jiayu Yao, Yuyao Ge, Yiwei Wang, Baolong Bi, Yujun Cai, Jiazhi Liu, Mingyu Li, Zhong-Zhi Li, Duzhen Zhang, Chenlin Zhou, Jiayi Mao, Tianze Xia, Jiafeng Guo, Shenghua Liu
date: 21-07-2025
---

# A Survey of Context Engineering for Large Language Models

This survey introduces Context Engineering as a formal discipline for optimizing the information given to Large Language Models (LLMs) during inference. [1] It provides a comprehensive taxonomy that breaks down Context Engineering into Foundational Components and System Implementations. [1] The foundational components include context retrieval, generation, processing, and management. [1] The survey then explores how these components are integrated into systems like Retrieval-Augmented Generation (RAG), memory systems, and multi-agent systems. [1] A key finding is the asymmetry between LLMs' advanced ability to understand complex contexts and their limited ability to generate sophisticated, long-form outputs. [1]

*   **Context Engineering:** A systematic approach to optimizing the information payloads for LLMs, moving beyond simple prompt design. [1]
*   **Foundational Components:** The core elements of Context Engineering are Context Retrieval and Generation, Context Processing, and Context Management. [1]
*   **System Implementations:** These components are integrated to create advanced systems such as Retrieval-Augmented Generation (RAG), Memory Systems, Tool-Integrated Reasoning, and Multi-Agent Systems. [1]
*   **Comprehension-Generation Gap:** LLMs show a significant disparity between their strong ability to understand complex information and their weaker ability to generate equally complex and lengthy outputs. [1]
*   **Future Directions:** The survey identifies the need for unified theoretical frameworks, improved scaling laws, and better multi-modal integration to advance the field. [1]